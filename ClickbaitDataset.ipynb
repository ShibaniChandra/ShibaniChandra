{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd877d1a",
   "metadata": {},
   "source": [
    "# Clickbait Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166b6db",
   "metadata": {},
   "source": [
    "Naive Bayes vs. Rocchio Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b1ac9",
   "metadata": {},
   "source": [
    "**Text classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2c32a",
   "metadata": {},
   "source": [
    "**Q1 (A)**<b> Click bait dataset </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c98ca9",
   "metadata": {},
   "source": [
    "This dataset contains headlines from various news sites such as ‘WikiNews’, ’New York Times’, ‘The Guardian’, ‘The Hindu’, ‘BuzzFeed’, ‘Upworthy’, ‘ViralNova’, ‘Thatscoop’, ‘Scoopwhoop’ and ‘ViralStories’. It has two columns first one contains headlines and the second one has numerical labels of clickbait in which 1 represents that it is clickbait and 0 represents that it is non-clickbait headline. The dataset contains total 32000 rows of which 50% are clickbait and other 50% are non-clickbait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190ee600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\pc\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (2.6.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.6.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.14)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries and packages\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string as s\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7630e",
   "metadata": {},
   "source": [
    "**A dataset to classify news headlines into clickbait or non-clickbait**\n",
    "\n",
    "Kaggle link for dataset = https://www.kaggle.com/datasets/amananandrai/clickbait-dataset?resource=download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8edfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should I Get Bings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which TV Female Friend Group Do You Belong In</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The New \"Star Wars: The Force Awakens\" Trailer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Vine Of New York On \"Celebrity Big Brothe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Couple Did A Stunning Photo Shoot With Their...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  clickbait\n",
       "0                                 Should I Get Bings          1\n",
       "1      Which TV Female Friend Group Do You Belong In          1\n",
       "2  The New \"Star Wars: The Force Awakens\" Trailer...          1\n",
       "3  This Vine Of New York On \"Celebrity Big Brothe...          1\n",
       "4  A Couple Did A Stunning Photo Shoot With Their...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset from local path\n",
    "\n",
    "clickBait_data= pd.read_csv('clickbait_data.csv')\n",
    "clickBait_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e62bc",
   "metadata": {},
   "source": [
    "**Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7797d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_2348\\33580579.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data = clickBait_data[~clickBait_data['headline'].astype(str).str.replace('.', '', 1).str.isnumeric()]\n"
     ]
    }
   ],
   "source": [
    "##Preprocessing\n",
    "\n",
    "# Remove rows with numeric (float or int) values in 'Job Description'\n",
    "data = clickBait_data[~clickBait_data['headline'].astype(str).str.replace('.', '', 1).str.isnumeric()]\n",
    "\n",
    "# Convert all text into lower case\n",
    "df_text = data['headline'].str.lower()\n",
    "\n",
    "# Remove email ids from the text\n",
    "df_text = df_text.replace({'<?([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+>?(\\s\\([A-Za-z ]*\\))?':''}, regex = True)    \n",
    "\n",
    "# Remove hyperlinks from the text\n",
    "df_text = df_text.replace({'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+':''}, regex = True)\n",
    "\n",
    "# Remove html tags\n",
    "df_text = df_text.replace({'<.*?>': ''}, regex = True)         \n",
    "\n",
    "# Remove non alphabet\n",
    "df_text = df_text.replace({'[^A-Za-z]': ' '}, regex = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee55bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from the text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "# Applying the function on the entire dataset\n",
    "\n",
    "df_text = df_text.apply(lambda desc: remove_stopwords(desc))  # remove stop words\n",
    "data['description after removal of stopwords']=df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578b0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Remove Stop Words, Tokenize and Lemmatize the text\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    clean_data = ' '.join(lemmatized_tokens)\n",
    "    return clean_data\n",
    "\n",
    "# Applying the lemmatization to the entire dataset\n",
    "data['preprocessed headline'] = data['description after removal of stopwords'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c783c5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                 bing\n",
      "1                        tv female friend group belong\n",
      "2             new star war force awakens trailer chill\n",
      "3    vine new york celebrity big brother fucking pe...\n",
      "4    couple stunning photo shoot baby learn inopera...\n",
      "Name: preprocessed headline, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['preprocessed headline'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a721cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into train set and test set\n",
    "\n",
    "x= data.headline\n",
    "y= data.clickbait\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f339c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26171    Sixteen Christian converts arrested in Iran; f...\n",
      "16224    Hiring of Isiah Thomas Angers Some F.I.U. Facu...\n",
      "27534       Fußball-Bundesliga 2007–08: Matchday 1 roundup\n",
      "27304       Taco Bell mascot Gidget dies from stroke at 15\n",
      "24836    China Takes Heavy Criticism Over Software Dire...\n",
      "Name: headline, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_x[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b95a3",
   "metadata": {},
   "source": [
    "**Vectorization of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b65b4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8537c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "train_vec= tfidf.fit_transform(train_x)\n",
    "test_vec= tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2dfe0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features extracted:\n",
      "20022\n",
      "\n",
      "The 100 features extracted from TF-IDF:\n",
      "\n",
      "['00' '000' '00s' '04' '05' '08' '08m' '09' '10' '100' '1000' '10000th'\n",
      " '1000blackgirls' '100k' '100m' '100th' '100ºf' '101' '101st' '102' '103'\n",
      " '104' '105' '106' '108' '109' '109th' '10th' '11' '110' '111' '112' '113'\n",
      " '114' '115' '116' '118th' '11k' '11n' '11th' '12' '120' '121' '1215'\n",
      " '122' '123' '125' '126' '127' '128' '12th' '13' '130' '132' '134' '137'\n",
      " '139' '13th' '14' '140' '147' '149' '14th' '15' '150' '152' '1525' '153'\n",
      " '154' '155' '159' '15bn' '16' '160' '162' '163' '165' '168' '16th' '17'\n",
      " '170' '1700' '17000' '172' '174' '175' '177' '17th' '18' '180' '18000'\n",
      " '1800s' '188' '18th' '19' '191' '1912' '1915' '1917' '1918']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features extracted:\")\n",
    "print(len(tfidf.get_feature_names_out()))\n",
    "print(\"\\nThe 100 features extracted from TF-IDF:\\n\")\n",
    "print(tfidf.get_feature_names_out()[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6bd483",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0d7361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e476445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_MN=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a3be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Naive Bayes Classification Model\n",
    "NB_MN.fit(train_vec,train_y)\n",
    "\n",
    "#Predict\n",
    "y_pred_NB= NB_MN.predict(test_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef6639",
   "metadata": {},
   "source": [
    "**Evaluation of Naive Bayes Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe7430bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model\n",
      "0.9731819280019328\n",
      "\n",
      "Accuracy of the model\n",
      "0.97225\n",
      "\n",
      "Accuracy of the model in percentage\n",
      "97.225 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "print(\"F1 score of the model\")\n",
    "print(f1_score(test_y,y_pred_NB))\n",
    "print(\"\\nAccuracy of the model\")\n",
    "print(accuracy_score(test_y,y_pred_NB))\n",
    "print(\"\\nAccuracy of the model in percentage\")\n",
    "print(accuracy_score(test_y,y_pred_NB)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfc86f",
   "metadata": {},
   "source": [
    "**Precision, Recall, F1-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8c01051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3925\n",
      "           1       0.96      0.99      0.97      4075\n",
      "\n",
      "    accuracy                           0.97      8000\n",
      "   macro avg       0.97      0.97      0.97      8000\n",
      "weighted avg       0.97      0.97      0.97      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e440c99",
   "metadata": {},
   "source": [
    "The matrix shows that the classifier performs well for both classes, with high precision, recall, and F1 score for both 0 and 1. The overall accuracy is also high, indicating that the classifier is able to correctly label the majority of instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fc36f",
   "metadata": {},
   "source": [
    "### Rocchio Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5496baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31081181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestCentroid()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestCentroid</label><div class=\"sk-toggleable__content\"><pre>NearestCentroid()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestCentroid()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Rocchio classifier model\n",
    "rocchio_clf = NearestCentroid()\n",
    "rocchio_clf.fit(train_vec, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57912153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Predict using Rocchio classifier\n",
    "y_pred_rocchio = rocchio_clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c545105",
   "metadata": {},
   "source": [
    "**Evaluation of Rocchio Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "400e5fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model\n",
      "0.8855694851960523\n",
      "\n",
      "Accuracy of the model\n",
      "0.89275\n",
      "\n",
      "Accuracy of the model in percentage\n",
      "89.275 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"F1 score of the model\")\n",
    "print(f1_score(test_y,y_pred_rocchio))\n",
    "print(\"\\nAccuracy of the model\")\n",
    "print(accuracy_score(test_y,y_pred_rocchio))\n",
    "print(\"\\nAccuracy of the model in percentage\")\n",
    "print(accuracy_score(test_y,y_pred_rocchio)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b93d8",
   "metadata": {},
   "source": [
    "**Precision, Recall, F1-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ece7ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      3925\n",
      "           1       0.97      0.81      0.89      4075\n",
      "\n",
      "    accuracy                           0.89      8000\n",
      "   macro avg       0.90      0.89      0.89      8000\n",
      "weighted avg       0.90      0.89      0.89      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifier\n",
    "print(classification_report(test_y, y_pred_rocchio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8e9fe",
   "metadata": {},
   "source": [
    "Class 0 performs better in terms of recall, while Class 1 has higher precision. The model's overall performance is balanced, with slightly better performance for Class 0 based on the F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd4ad4",
   "metadata": {},
   "source": [
    "*Looking at the classification report for both the models we see that Naive Bayes has more accuracy as compared to Rocchio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59872abe",
   "metadata": {},
   "source": [
    "**QB 1(a)**<b> Compare the performance of both classifiers in terms of accuracy, precision, recall, and F1-score </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d0c64",
   "metadata": {},
   "source": [
    "**F1 Score**: The F1 score is a metric that balances precision and recall. A higher F1 score indicates better performance in terms of both precision and recall. In this case, the Naive Bayes model achieved a higher F1 score (0.973) compared to the Rocchio algorithm (0.886). This suggests that the Naive Bayes model performs better overall in terms of correctly identifying both positive and negative instances.\n",
    "\n",
    "**Accuracy**: Accuracy represents the proportion of correctly classified instances out of the total number of instances. The Naive Bayes model achieved an accuracy of 97.225%, while the Rocchio algorithm achieved an accuracy of 89.275%. This indicates that the Naive Bayes model has a higher overall accuracy in classifying instances compared to the Rocchio algorithm.\n",
    "\n",
    "**Performance Comparison**: Based on the F1 scores and accuracy scores, we can conclude that the Naive Bayes model outperforms the Rocchio algorithm in terms of both F1 score and accuracy. The Naive Bayes model has higher precision, recall, and overall accuracy compared to the Rocchio algorithm.\n",
    "\n",
    "**Consideration of Trade-offs**: While the Naive Bayes model performs better overall, it's important to consider the specific trade-offs between precision, recall, and computational complexity when choosing between models. The Rocchio algorithm may have lower performance metrics but could be computationally less expensive or easier to interpret, depending on the specific requirements of the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489d6e6",
   "metadata": {},
   "source": [
    "**QB 2(b)**<b> Discuss the differences between Naive Bayes and Rocchio classifiers in terms of underlying assumptions, training process, and performance on different types of datasets </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a94a73",
   "metadata": {},
   "source": [
    "Naive Bayes and Rocchio classifiers differ in terms of their underlying assumptions, training processes, and performance on different types of datasets.\n",
    "\n",
    "**Underlying Assumptions**:\n",
    "- **Naive Bayes**:\n",
    "\t<br> Assumption: Naive Bayes classifiers are based on Bayes' theorem and assume that features are conditionally independent given the class label. This is a strong and often unrealistic assumption, especially in cases where features are correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0df0d",
   "metadata": {},
   "source": [
    "\n",
    "- **Rocchio**:\n",
    "    <br>Assumption: Rocchio classifiers are based on the vector space model and assume that documents belonging to the same class should be close to each other in the feature space. It doesn't assume independence among features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1eafef",
   "metadata": {},
   "source": [
    "<b> Training Process </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4ea89",
   "metadata": {},
   "source": [
    "- **Naive Bayes**: \n",
    "<br> Estimates the probability of each feature value occurring given a class label using the training data. It then uses Bayes' theorem to calculate the probability of a class label given a new data point. The model can be incrementally updated with new training data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a157eb",
   "metadata": {},
   "source": [
    "- **Rocchio**: \n",
    "<br> Calculates a centroid vector for each class by averaging the feature vectors of the training data points belonging to that class. New data points are classified based on their similarity (usually cosine similarity) to the class centroids. Rocchio can be sensitive to outliers, and the prototype vectors can be updated iteratively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cdd5a",
   "metadata": {},
   "source": [
    "<b> Performance on Different Types of Datasets: </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba269e",
   "metadata": {},
   "source": [
    "**Naive Bayes**:\n",
    "- Generally performs well with categorical features and datasets where the independence assumption is somewhat reasonable.\n",
    "- Can struggle with high-dimensional data or datasets with complex relationships between features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657a31a",
   "metadata": {},
   "source": [
    "**Rocchio**:\n",
    "- Often performs well with text data represented using techniques like TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "- May not handle datasets with non-convex or multimodal class distributions well (where a class can't be neatly represented by a single centroid).\n",
    "- Sensitive to outliers and noise in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec885b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
